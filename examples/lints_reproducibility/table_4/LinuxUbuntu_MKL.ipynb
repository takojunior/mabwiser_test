{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fitted-passage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.10 (default, Feb 26 2021, 18:47:35) \n",
      "[GCC 7.3.0]\n",
      "1.18.5\n",
      "0.24.1\n",
      "1.15.5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "print(sys.version)\n",
    "print(np.__version__)\n",
    "print(sklearn.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-thousand",
   "metadata": {},
   "source": [
    "## Deep Bayesian Bandits Reproducibility\n",
    "\n",
    "This notebook explores the reproducibility around the [Deep Bayesian Bandits](https://github.com/tensorflow/models/tree/archive/research/deep_contextual_bandits) work by Google. We look at the LinTS implementation, which forms the baseline of their experiments.\n",
    "\n",
    "In order to run these experiments, please perform the steps below:\n",
    "- Clone the [tensorflow models repo](https://github.com/tensorflow/models), switch to the `archive` branch, and copy `models/research/deep_contextual_bandits/bandits` folder to this directory.\n",
    "- Run the cell below to overwrite the LinTS implementation file. This updates the multivariate sampling such that we can select the method to use while sampling, between SVD and Cholesky. Note that the SVD method was used in the original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hungry-anderson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting bandits/algorithms/linear_full_posterior_sampling.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile bandits/algorithms/linear_full_posterior_sampling.py\n",
    "# Copyright 2018 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Contextual algorithm that keeps a full linear posterior for each arm.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import invgamma\n",
    "\n",
    "from bandits.core.bandit_algorithm import BanditAlgorithm\n",
    "from bandits.core.contextual_dataset import ContextualDataset\n",
    "\n",
    "\n",
    "class LinearFullPosteriorSampling(BanditAlgorithm):\n",
    "  \"\"\"Thompson Sampling with independent linear models and unknown noise var.\"\"\"\n",
    "\n",
    "  def __init__(self, name, hparams):\n",
    "    \"\"\"Initialize posterior distributions and hyperparameters.\n",
    "\n",
    "    Assume a linear model for each action i: reward = context^T beta_i + noise\n",
    "    Each beta_i has a Gaussian prior (lambda parameter), each sigma2_i (noise\n",
    "    level) has an inverse Gamma prior (a0, b0 parameters). Mean, covariance,\n",
    "    and precision matrices are initialized, and the ContextualDataset created.\n",
    "\n",
    "    Args:\n",
    "      name: Name of the algorithm.\n",
    "      hparams: Hyper-parameters of the algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    self.name = name\n",
    "    self.hparams = hparams\n",
    "    self.rng = np.random.default_rng(self.hparams.seed)\n",
    "\n",
    "    # Gaussian prior for each beta_i\n",
    "    self._lambda_prior = self.hparams.lambda_prior\n",
    "\n",
    "    self.mu = [\n",
    "        np.zeros(self.hparams.context_dim + 1)\n",
    "        for _ in range(self.hparams.num_actions)\n",
    "    ]\n",
    "\n",
    "    self.cov = [(1.0 / self.lambda_prior) * np.eye(self.hparams.context_dim + 1)\n",
    "                for _ in range(self.hparams.num_actions)]\n",
    "\n",
    "    self.precision = [\n",
    "        self.lambda_prior * np.eye(self.hparams.context_dim + 1)\n",
    "        for _ in range(self.hparams.num_actions)\n",
    "    ]\n",
    "\n",
    "    # Inverse Gamma prior for each sigma2_i\n",
    "    self._a0 = self.hparams.a0\n",
    "    self._b0 = self.hparams.b0\n",
    "\n",
    "    self.a = [self._a0 for _ in range(self.hparams.num_actions)]\n",
    "    self.b = [self._b0 for _ in range(self.hparams.num_actions)]\n",
    "\n",
    "    self.t = 0\n",
    "    self.data_h = ContextualDataset(hparams.context_dim,\n",
    "                                    hparams.num_actions,\n",
    "                                    intercept=True)\n",
    "\n",
    "  def action(self, context):\n",
    "    \"\"\"Samples beta's from posterior, and chooses best action accordingly.\n",
    "\n",
    "    Args:\n",
    "      context: Context for which the action need to be chosen.\n",
    "\n",
    "    Returns:\n",
    "      action: Selected action for the context.\n",
    "    \"\"\"\n",
    "\n",
    "    # Round robin until each action has been selected \"initial_pulls\" times\n",
    "    if self.t < self.hparams.num_actions * self.hparams.initial_pulls:\n",
    "      return self.t % self.hparams.num_actions\n",
    "\n",
    "    # Sample sigma2, and beta conditional on sigma2\n",
    "    sigma2_s = [\n",
    "        self.b[i] * invgamma.rvs(self.a[i])\n",
    "        for i in range(self.hparams.num_actions)\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        if self.hparams.method == 'default':\n",
    "            beta_s = [\n",
    "              np.random.multivariate_normal(self.mu[i], sigma2_s[i] * self.cov[i])\n",
    "              for i in range(self.hparams.num_actions)\n",
    "            ]\n",
    "        else:\n",
    "            beta_s = [\n",
    "                self.rng.multivariate_normal(self.mu[i], sigma2_s[i] * self.cov[i], method=self.hparams.method)\n",
    "                for i in range(self.hparams.num_actions)\n",
    "            ]\n",
    "    except np.linalg.LinAlgError as e:\n",
    "      # Sampling could fail if covariance is not positive definite\n",
    "      print('Exception when sampling from {}.'.format(self.name))\n",
    "      print('Details: {} | {}.'.format(e.message, e.args))\n",
    "      d = self.hparams.context_dim + 1\n",
    "      beta_s = [\n",
    "          np.random.multivariate_normal(np.zeros((d)), np.eye(d))\n",
    "          for i in range(self.hparams.num_actions)\n",
    "      ]\n",
    "\n",
    "    # Compute sampled expected values, intercept is last component of beta\n",
    "    vals = [\n",
    "        np.dot(beta_s[i][:-1], context.T) + beta_s[i][-1]\n",
    "        for i in range(self.hparams.num_actions)\n",
    "    ]\n",
    "\n",
    "    return np.argmax(vals)\n",
    "\n",
    "  def update(self, context, action, reward):\n",
    "    \"\"\"Updates action posterior using the linear Bayesian regression formula.\n",
    "\n",
    "    Args:\n",
    "      context: Last observed context.\n",
    "      action: Last observed action.\n",
    "      reward: Last observed reward.\n",
    "    \"\"\"\n",
    "\n",
    "    self.t += 1\n",
    "    self.data_h.add(context, action, reward)\n",
    "\n",
    "    # Update posterior of action with formulas: \\beta | x,y ~ N(mu_q, cov_q)\n",
    "    x, y = self.data_h.get_data(action)\n",
    "\n",
    "    # The algorithm could be improved with sequential update formulas (cheaper)\n",
    "    s = np.dot(x.T, x)\n",
    "\n",
    "    # Some terms are removed as we assume prior mu_0 = 0.\n",
    "    precision_a = s + self.lambda_prior * np.eye(self.hparams.context_dim + 1)\n",
    "    cov_a = np.linalg.inv(precision_a)\n",
    "    mu_a = np.dot(cov_a, np.dot(x.T, y))\n",
    "\n",
    "    # Inverse Gamma posterior update\n",
    "    a_post = self.a0 + x.shape[0] / 2.0\n",
    "    b_upd = 0.5 * (np.dot(y.T, y) - np.dot(mu_a.T, np.dot(precision_a, mu_a)))\n",
    "    b_post = self.b0 + b_upd\n",
    "\n",
    "    # Store new posterior distributions\n",
    "    self.mu[action] = mu_a\n",
    "    self.cov[action] = cov_a\n",
    "    self.precision[action] = precision_a\n",
    "    self.a[action] = a_post\n",
    "    self.b[action] = b_post\n",
    "\n",
    "  @property\n",
    "  def a0(self):\n",
    "    return self._a0\n",
    "\n",
    "  @property\n",
    "  def b0(self):\n",
    "    return self._b0\n",
    "\n",
    "  @property\n",
    "  def lambda_prior(self):\n",
    "    return self._lambda_prior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-advocate",
   "metadata": {},
   "source": [
    "We replicate the [quick start example](https://github.com/tensorflow/models/blob/archive/research/deep_contextual_bandits/example_main.py) from the Deep Contextual Bandits research repo below, focusing on just LinTS, and evaluating the cumulative reward at the end. Note that all the seeds are set, such that the cumulative reward should be the same when the code is run in the same environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fewer-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "\n",
    "from bandits.data.data_sampler import sample_mushroom_data\n",
    "from bandits.core.contextual_bandit import run_contextual_bandit\n",
    "from bandits.algorithms.linear_full_posterior_sampling import LinearFullPosteriorSampling\n",
    "\n",
    "if type(tf.contrib) != type(tf):\n",
    "    tf.contrib._warning = None\n",
    "\n",
    "def sample_data(num_contexts):\n",
    "    num_actions = 2\n",
    "    context_dim = 117\n",
    "    file_name = 'mushroom.data'\n",
    "    dataset, opt_mushroom = sample_mushroom_data(file_name, num_contexts)\n",
    "    opt_rewards, opt_actions = opt_mushroom\n",
    "    return dataset, opt_rewards, opt_actions, num_actions, context_dim\n",
    "\n",
    "# Problem parameters\n",
    "num_contexts = 2000\n",
    "\n",
    "# Create dataset\n",
    "np.random.seed(42)\n",
    "sampled_vals = sample_data(num_contexts)\n",
    "dataset, opt_rewards, opt_actions, num_actions, context_dim = sampled_vals\n",
    "\n",
    "def run_dbb(random_option):\n",
    "    np.random.seed(42)\n",
    "    hparams_linear = tf.contrib.training.HParams(num_actions=num_actions,\n",
    "                                                 context_dim=context_dim,\n",
    "                                                 a0=6,\n",
    "                                                 b0=6,\n",
    "                                                 lambda_prior=0.25,\n",
    "                                                 initial_pulls=2,\n",
    "                                                 seed=42,\n",
    "                                                 method=random_option)\n",
    "\n",
    "    algos = [\n",
    "          LinearFullPosteriorSampling('LinFullPost', hparams_linear),\n",
    "    ]\n",
    "    t_init = time.time()\n",
    "    results = run_contextual_bandit(context_dim, num_actions, dataset, algos)\n",
    "    _, h_rewards = results\n",
    "\n",
    "\n",
    "    reward = np.sum(h_rewards[:, 0])\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-leader",
   "metadata": {},
   "source": [
    "### Option 1\n",
    "We use the default implementation, which uses `np.random.multivariate_random`, and set the global seed to ensure reproducibility in a single environment. Note that this is the same as using `np.random.RandomState`, as the global seed sets the random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d18be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3475.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_reward = run_dbb('default')\n",
    "default_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-graphic",
   "metadata": {},
   "source": [
    "### Option 2\n",
    "We use the new `Generator` class with default parameters, which internally uses SVD for decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aefc1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3540.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_reward = run_dbb('svd')\n",
    "svd_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c42811b",
   "metadata": {},
   "source": [
    "### Option 3\n",
    "We use Cholesky decomposition with the new Generator class. Our hypothesis is that this will produce reproducible results across different environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b31cbc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4140.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cholesky_reward = run_dbb('cholesky')\n",
    "cholesky_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-producer",
   "metadata": {},
   "source": [
    "We save all the results for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08aca1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>svd</th>\n",
       "      <th>cholesky</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>env</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinuxUbuntu_MKL</th>\n",
       "      <td>3475.0</td>\n",
       "      <td>3540.0</td>\n",
       "      <td>4140.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 default     svd  cholesky\n",
       "env                                       \n",
       "LinuxUbuntu_MKL   3475.0  3540.0    4140.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = pd.DataFrame({\n",
    "    'env': ['LinuxUbuntu_MKL'],\n",
    "    'default': [default_reward],\n",
    "    'svd': [svd_reward],\n",
    "    'cholesky': [cholesky_reward],\n",
    "}).set_index('env')\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c194af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('output', exist_ok=True)\n",
    "rewards.to_csv(os.path.join('output', 'linuxubuntu_mkl_rewards.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
