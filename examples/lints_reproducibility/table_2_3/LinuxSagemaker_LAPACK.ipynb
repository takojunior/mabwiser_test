{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import platform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from mabwiser.mab import MAB, LearningPolicy\n",
    "from mabwiser.linear import _RidgeRegression, _Linear\n",
    "\n",
    "class LinTSExample(_RidgeRegression):\n",
    "    def predict(self, x):\n",
    "        if self.scaler is not None:\n",
    "            x = self._scale_predict_context(x) \n",
    "        covar = np.dot(self.alpha**2, self.A_inv)\n",
    "        beta_sampled = rng.multivariate_normal(self.beta, covar)        \n",
    "        return np.dot(x, beta_sampled)\n",
    "    \n",
    "class LinearExample(_Linear):\n",
    "    factory = {\"ts\": LinTSExample}\n",
    "\n",
    "    def __init__(self, rng, arms, n_jobs=1, backend=None, l2_lambda=1, alpha=1, regression='ts', arm_to_scaler = None):\n",
    "        super().__init__(rng, arms, n_jobs, backend, l2_lambda, alpha, regression)\n",
    "       \n",
    "        self.l2_lambda = l2_lambda\n",
    "        self.alpha = alpha\n",
    "        self.regression = regression\n",
    "\n",
    "        # Create ridge regression model for each arm\n",
    "        self.num_features = None\n",
    "\n",
    "        if arm_to_scaler is None:\n",
    "            arm_to_scaler = dict((arm, None) for arm in arms)\n",
    "\n",
    "        self.arm_to_model = dict((arm, LinearExample.factory.get(regression)(rng, l2_lambda,\n",
    "                                                                       alpha, arm_to_scaler[arm])) for arm in arms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Linux-4.14.225-121.362.amzn1.x86_64-x86_64-with-glibc2.9'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platform.platform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('movielens_users.csv')\n",
    "responses = pd.read_csv('movielens_responses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = users[users['set']=='train']\n",
    "test = users[users['set']=='test']\n",
    "\n",
    "train = train.merge(responses, how='left', on='user id')\n",
    "context_features = [c for c in users.columns if c not in ['user id', 'set']]\n",
    "\n",
    "decisions = MAB._convert_array(train['item id'])\n",
    "rewards = MAB._convert_array(train['rated'])\n",
    "contexts = MAB._convert_matrix(train[context_features]).astype('float')\n",
    "\n",
    "test_contexts = MAB._convert_matrix(test[context_features]).astype('float')\n",
    "\n",
    "scaler = pickle.load(open('movielens_scaler.pkl', 'rb'))\n",
    "\n",
    "contexts = scaler.transform(contexts)\n",
    "test_contexts = scaler.transform(test_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LinTSExample at 0x7f72aeb0ec50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.RandomState(seed=11)\n",
    "arms = list(responses['item id'].unique())\n",
    "\n",
    "mab = LinearExample(rng=rng, arms=arms, l2_lambda=10, alpha=1, regression='ts', n_jobs=1, backend=None)\n",
    "mab.arm_to_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03593678774680008"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mab.fit(decisions, rewards, contexts)\n",
    "expectations = mab.predict_expectations(test_contexts)\n",
    "\n",
    "expectations[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mab, open(os.path.join('output', 'sgm_ml_mab2.pkl'), 'wb'))\n",
    "pickle.dump(expectations, open(os.path.join('output', 'sgm_ml_expectations2.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cholesky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mabwiser.linear._LinTS at 0x7f164a00fda0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arms = list(responses['item id'].unique())\n",
    "mab = MAB(arms=arms, learning_policy=LearningPolicy.LinTS(l2_lambda=10, alpha=1), n_jobs=1, backend=None, seed=11)\n",
    "mab._imp.arm_to_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2992644622589859"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mab.fit(decisions, rewards, contexts)\n",
    "expectations = mab.predict_expectations(test_contexts)\n",
    "\n",
    "expectations[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mab, open(os.path.join('output', 'sgm_ml_ch_mab2.pkl'), 'wb'))\n",
    "pickle.dump(expectations, open(os.path.join('output', 'sgm_ml_ch_expectations2.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07936336, -0.00871014,  0.03361507, -0.02956334, -0.02518599,\n",
       "        0.02451638,  0.00301226,  0.05208961,  0.01395249,  0.01485094,\n",
       "        0.01148366, -0.02269606,  0.01052057, -0.01819606, -0.02941985,\n",
       "        0.01537429, -0.00853869,  0.00354568, -0.01047156,  0.00412024,\n",
       "       -0.01159282,  0.00889091,  0.01726125, -0.01977439, -0.00274761])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mab._imp.arm_to_model[1].beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
